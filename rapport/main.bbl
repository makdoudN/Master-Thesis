\begin{thebibliography}{10}

\bibitem{DBLP:journals/corr/BeattieLTWWKLGV16}
{\sc C.~Beattie, J.~Z. Leibo, D.~Teplyashin, T.~Ward, M.~Wainwright,
  H.~K{\"{u}}ttler, A.~Lefrancq, S.~Green, V.~Vald{\'{e}}s, A.~Sadik,
  J.~Schrittwieser, K.~Anderson, S.~York, M.~Cant, A.~Cain, A.~Bolton,
  S.~Gaffney, H.~King, D.~Hassabis, S.~Legg, and S.~Petersen}, {\em Deepmind
  lab}, CoRR, abs/1612.03801 (2016).

\bibitem{neuronebayes}
{\sc C.~{Blundell}, J.~{Cornebise}, K.~{Kavukcuoglu}, and D.~{Wierstra}}, {\em
  {Weight Uncertainty in Neural Networks}}, ArXiv e-prints,  (2015).

\bibitem{1606.01540}
{\sc G.~Brockman, V.~Cheung, L.~Pettersson, J.~Schneider, J.~Schulman, J.~Tang,
  and W.~Zaremba}, {\em Openai gym}, 2016.

\bibitem{2017arXiv170504862C}
{\sc A.~V. {Clemente}, H.~N. {Castej{\'o}n}, and A.~{Chandra}}, {\em {Efficient
  Parallel Methods for Deep Reinforcement Learning}}, ArXiv e-prints,  (2017).

\bibitem{hierarchicalcuriosity}
{\sc N.~Dilokthanakul, C.~Kaplanis, N.~Pawlowski, and M.~Shanahan}, {\em
  Feature control as intrinsic motivation for hierarchical reinforcement
  learning}, CoRR, abs/1705.06769 (2017).

\bibitem{LSTM}
{\sc S.~Hochreiter and J.~Schmidhuber}, {\em Long short-term memory}, Neural
  Comput., 9 (1997), pp.~1735--1780.

\bibitem{curiositydriven}
{\sc R.~Houthooft, X.~Chen, Y.~Duan, J.~Schulman, F.~D. Turck, and P.~Abbeel},
  {\em Curiosity-driven exploration in deep reinforcement learning via bayesian
  neural networks.}, CoRR, abs/1605.09674 (2016).

\bibitem{VIME}
{\sc R.~Houthooft, X.~Chen, Y.~Duan, J.~Schulman, F.~D. Turck, and P.~Abbeel},
  {\em Curiosity-driven exploration in deep reinforcement learning via bayesian
  neural networks}, CoRR, abs/1605.09674 (2016).

\bibitem{empowerment}
{\sc T.~Jung, D.~Polani, and P.~Stone}, {\em Empowerment for continuous
  agent-environment systems}, CoRR, abs/1201.6583 (2012).

\bibitem{DBLP:journals/corr/KempkaWRTJ16}
{\sc M.~Kempka, M.~Wydmuch, G.~Runc, J.~Toczek, and W.~Jaskowski}, {\em
  Vizdoom: {A} doom-based {AI} research platform for visual reinforcement
  learning}, CoRR, abs/1605.02097 (2016).

\bibitem{Merkel:2014:DLL:2600239.2600241}
{\sc D.~Merkel}, {\em Docker: Lightweight linux containers for consistent
  development and deployment}, Linux J., 2014 (2014).

\bibitem{DBLP:journals/corr/MnihBMGLHSK16}
{\sc V.~Mnih, A.~P. Badia, M.~Mirza, A.~Graves, T.~P. Lillicrap, T.~Harley,
  D.~Silver, and K.~Kavukcuoglu}, {\em Asynchronous methods for deep
  reinforcement learning}, CoRR, abs/1602.01783 (2016).

\bibitem{2013arXiv1312.5602M}
{\sc V.~{Mnih}, K.~{Kavukcuoglu}, D.~{Silver}, A.~{Graves}, I.~{Antonoglou},
  D.~{Wierstra}, and M.~{Riedmiller}}, {\em {Playing Atari with Deep
  Reinforcement Learning}}, ArXiv e-prints,  (2013).

\bibitem{mnih-dqn-2015}
{\sc V.~Mnih, K.~Kavukcuoglu, D.~Silver, A.~A. Rusu, J.~Veness, M.~G.
  Bellemare, A.~Graves, M.~Riedmiller, A.~K. Fidjeland, G.~Ostrovski,
  S.~Petersen, C.~Beattie, A.~Sadik, I.~Antonoglou, H.~King, D.~Kumaran,
  D.~Wierstra, S.~Legg, and D.~Hassabis}, {\em Human-level control through deep
  reinforcement learning}, Nature, 518 (2015), pp.~529--533.

\bibitem{empowerment2}
{\sc S.~{Mohamed} and D.~{Jimenez Rezende}}, {\em {Variational Information
  Maximisation for Intrinsically Motivated Reinforcement Learning}}, ArXiv
  e-prints,  (2015).

\bibitem{empowerment3}
{\sc C.~{Salge}, C.~{Glackin}, and D.~{Polani}}, {\em {Empowerment -- an
  Introduction}}, ArXiv e-prints,  (2013).

\bibitem{REPLAY}
{\sc T.~Schaul, J.~Quan, I.~Antonoglou, and D.~Silver}, {\em Prioritized
  experience replay}, CoRR, abs/1511.05952 (2015).

\bibitem{GAE}
{\sc J.~Schulman, P.~Moritz, S.~Levine, M.~I. Jordan, and P.~Abbeel}, {\em
  High-dimensional continuous control using generalized advantage estimation},
  CoRR, abs/1506.02438 (2015).

\bibitem{blogPerceptron}
{\sc sebastian raschka}, {\em Single-layer neural networks and gradient
  descent}, 2015.

\bibitem{policygradient}
{\sc R.~S. Sutton, D.~Mcallester, S.~Singh, and Y.~Mansour}, {\em Policy
  gradient methods for reinforcement learning with function approximation}, in
  In Advances in Neural Information Processing Systems 12, MIT Press, 2000,
  pp.~1057--1063.

\bibitem{DDQN}
{\sc H.~van Hasselt, A.~Guez, and D.~Silver}, {\em Deep reinforcement learning
  with double q-learning}, CoRR, abs/1509.06461 (2015).

\bibitem{DUEL}
{\sc Z.~Wang, N.~de~Freitas, and M.~Lanctot}, {\em Dueling network
  architectures for deep reinforcement learning}, CoRR, abs/1511.06581 (2015).

\bibitem{Watkins92q-learning}
{\sc C.~J. C.~H. Watkins and P.~Dayan}, {\em Q-learning}, in Machine Learning,
  1992, pp.~279--292.

\bibitem{Williams1992}
{\sc R.~J. Williams}, {\em Simple statistical gradient-following algorithms for
  connectionist reinforcement learning}, Machine Learning, 8 (1992),
  pp.~229--256.

\end{thebibliography}
