@inproceedings{DBLP:conf/atal/NavarroFM15,
  author    = {Laurent Navarro and
               Fabien Flacher and
               Christophe Meyer},
  title     = {SE-Star: {A} Large-Scale Human Behavior Simulation for Planning, Decision-Making
               and Training},
  booktitle = {Proceedings of the 2015 International Conference on Autonomous Agents
               and Multiagent Systems, {AAMAS} 2015, Istanbul, Turkey, May 4-8, 2015},
  pages     = {1939--1940},
  year      = {2015},
  crossref  = {DBLP:conf/atal/2015},
  url       = {http://dl.acm.org/citation.cfm?id=2773514},
  timestamp = {Fri, 15 May 2015 17:42:53 +0200},
  biburl    = {http://dblp2.uni-trier.de/rec/bib/conf/atal/NavarroFM15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@proceedings{DBLP:conf/atal/2015,
  editor    = {Gerhard Weiss and
               Pinar Yolum and
               Rafael H. Bordini and
               Edith Elkind},
  title     = {Proceedings of the 2015 International Conference on Autonomous Agents
               and Multiagent Systems, {AAMAS} 2015, Istanbul, Turkey, May 4-8, 2015},
  publisher = {{ACM}},
  year      = {2015},
  url       = {http://dl.acm.org/citation.cfm?id=2772879},
  isbn      = {978-1-4503-3413-6},
  timestamp = {Fri, 15 May 2015 16:18:42 +0200},
  biburl    = {http://dblp2.uni-trier.de/rec/bib/conf/atal/2015},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}


@online{blogPerceptron,
  author = {sebastian raschka},
  title = {Single-Layer Neural Networks and Gradient Descent},
  year = 2015 ,
  url = {http://sebastianraschka.com/Articles/2015_singlelayer_neurons.html},
  urldate = {2015}
}

@ARTICLE{2017arXiv170504862C,
   author = {{Clemente}, A.~V. and {Castej{\'o}n}, H.~N. and {Chandra}, A.
	},
    title = "{Efficient Parallel Methods for Deep Reinforcement Learning}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1705.04862},
 primaryClass = "cs.LG",
 keywords = {Computer Science - Learning},
     year = 2017,
    month = may,
   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170504862C},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{DBLP:journals/corr/KempkaWRTJ16,
  author    = {Michal Kempka and
               Marek Wydmuch and
               Grzegorz Runc and
               Jakub Toczek and
               Wojciech Jaskowski},
  title     = {ViZDoom: {A} Doom-based {AI} Research Platform for Visual Reinforcement
               Learning},
  journal   = {CoRR},
  volume    = {abs/1605.02097},
  year      = {2016},
  url       = {http://arxiv.org/abs/1605.02097},
  timestamp = {Wed, 07 Jun 2017 14:41:20 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/KempkaWRTJ16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{DBLP:journals/corr/BeattieLTWWKLGV16,
  author    = {Charles Beattie and
               Joel Z. Leibo and
               Denis Teplyashin and
               Tom Ward and
               Marcus Wainwright and
               Heinrich K{\"{u}}ttler and
               Andrew Lefrancq and
               Simon Green and
               V{\'{\i}}ctor Vald{\'{e}}s and
               Amir Sadik and
               Julian Schrittwieser and
               Keith Anderson and
               Sarah York and
               Max Cant and
               Adam Cain and
               Adrian Bolton and
               Stephen Gaffney and
               Helen King and
               Demis Hassabis and
               Shane Legg and
               Stig Petersen},
  title     = {DeepMind Lab},
  journal   = {CoRR},
  volume    = {abs/1612.03801},
  year      = {2016},
  url       = {http://arxiv.org/abs/1612.03801},
  timestamp = {Wed, 07 Jun 2017 14:42:49 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/BeattieLTWWKLGV16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@misc{1606.01540,
        Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
        Title = {OpenAI Gym},
        Year = {2016},
        Eprint = {arXiv:1606.01540},
}

@article{DBLP:journals/corr/MnihBMGLHSK16,
  author    = {Volodymyr Mnih and
               Adri{\`{a}} Puigdom{\`{e}}nech Badia and
               Mehdi Mirza and
               Alex Graves and
               Timothy P. Lillicrap and
               Tim Harley and
               David Silver and
               Koray Kavukcuoglu},
  title     = {Asynchronous Methods for Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1602.01783},
  year      = {2016},
  url       = {http://arxiv.org/abs/1602.01783},
  timestamp = {Wed, 07 Jun 2017 14:43:09 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/MnihBMGLHSK16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}



@article{Merkel:2014:DLL:2600239.2600241,
 author = {Merkel, Dirk},
 title = {Docker: Lightweight Linux Containers for Consistent Development and Deployment},
 journal = {Linux J.},
 issue_date = {March 2014},
 volume = {2014},
 number = {239},
 month = mar,
 year = {2014},
 issn = {1075-3583},
 articleno = {2},
 url = {http://dl.acm.org/citation.cfm?id=2600239.2600241},
 acmid = {2600241},
 publisher = {Belltown Media},
 address = {Houston, TX},
} 


@article{mnih-dqn-2015,
	Author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	Date = {2015/02/26/print},
	Date-Added = {2015-03-03 15:43:42 +0000},
	Date-Modified = {2015-03-03 15:43:42 +0000},
	Day = {26},
	Isbn = {0028-0836},
	Journal = {Nature},
	L3 = {10.1038/nature14236; http://www.nature.com/nature/journal/v518/n7540/abs/nature14236.html#supplementary-information},
	M3 = {Letter},
	Month = {02},
	Number = {7540},
	Pages = {529--533},
	Publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	Title = {Human-level control through deep reinforcement learning},
	Ty = {JOUR},
	Url = {http://dx.doi.org/10.1038/nature14236},
	Volume = {518},
	Year = {2015},
}

@ARTICLE{2013arXiv1312.5602M,
   author = {{Mnih}, V. and {Kavukcuoglu}, K. and {Silver}, D. and {Graves}, A. and 
	{Antonoglou}, I. and {Wierstra}, D. and {Riedmiller}, M.},
    title = "{Playing Atari with Deep Reinforcement Learning}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1312.5602},
 primaryClass = "cs.LG",
 keywords = {Computer Science - Learning},
     year = 2013,
    month = dec,
   adsurl = {http://adsabs.harvard.edu/abs/2013arXiv1312.5602M},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@INPROCEEDINGS{Watkins92q-learning,
    author = {Christopher J. C. H. Watkins and Peter Dayan},
    title = {Q-learning},
    booktitle = {Machine Learning},
    year = {1992},
    pages = {279--292}
}

@article{GAE,
  author    = {John Schulman and
               Philipp Moritz and
               Sergey Levine and
               Michael I. Jordan and
               Pieter Abbeel},
  title     = {High-Dimensional Continuous Control Using Generalized Advantage Estimation},
  journal   = {CoRR},
  volume    = {abs/1506.02438},
  year      = {2015},
  url       = {http://arxiv.org/abs/1506.02438},
  timestamp = {Wed, 07 Jun 2017 14:41:00 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/SchulmanMLJA15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
  
  
  @article{REPLAY,
  author    = {Tom Schaul and
               John Quan and
               Ioannis Antonoglou and
               David Silver},
  title     = {Prioritized Experience Replay},
  journal   = {CoRR},
  volume    = {abs/1511.05952},
  year      = {2015},
  url       = {http://arxiv.org/abs/1511.05952},
  timestamp = {Wed, 07 Jun 2017 14:42:32 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/SchaulQAS15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{DDQN,
  author    = {Hado van Hasselt and
               Arthur Guez and
               David Silver},
  title     = {Deep Reinforcement Learning with Double Q-learning},
  journal   = {CoRR},
  volume    = {abs/1509.06461},
  year      = {2015},
  url       = {http://arxiv.org/abs/1509.06461},
  timestamp = {Wed, 07 Jun 2017 14:40:43 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/HasseltGS15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{DUEL,
  author    = {Ziyu Wang and
               Nando de Freitas and
               Marc Lanctot},
  title     = {Dueling Network Architectures for Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1511.06581},
  year      = {2015},
  url       = {http://arxiv.org/abs/1511.06581},
  timestamp = {Tue, 08 Aug 2017 15:06:57 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/WangFL15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{CURIOSITY,
  author    = {Deepak Pathak and
               Pulkit Agrawal and
               Alexei A. Efros and
               Trevor Darrell},
  title     = {Curiosity-driven Exploration by Self-supervised Prediction},
  journal   = {CoRR},
  volume    = {abs/1705.05363},
  year      = {2017},
  url       = {http://arxiv.org/abs/1705.05363},
  timestamp = {Wed, 07 Jun 2017 14:41:47 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/PathakAED17},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@book{DEEPLEARNING,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}


@article{LSTM,
 author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
 title = {Long Short-Term Memory},
 journal = {Neural Comput.},
 issue_date = {November 15, 1997},
 volume = {9},
 number = {8},
 month = nov,
 year = {1997},
 issn = {0899-7667},
 pages = {1735--1780},
 numpages = {46},
 url = {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
 doi = {10.1162/neco.1997.9.8.1735},
 acmid = {1246450},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
} 


@article{hierarchicalcuriosity,
  author    = {Nat Dilokthanakul and
               Christos Kaplanis and
               Nick Pawlowski and
               Murray Shanahan},
  title     = {Feature Control as Intrinsic Motivation for Hierarchical Reinforcement
               Learning},
  journal   = {CoRR},
  volume    = {abs/1705.06769},
  year      = {2017},
  url       = {http://arxiv.org/abs/1705.06769},
  timestamp = {Wed, 07 Jun 2017 14:41:09 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/DilokthanakulKP17},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{curiositydriven,
  added-at = {2016-06-01T00:00:00.000+0200},
  author = {Houthooft, Rein and Chen, Xi and Duan, Yan and Schulman, John and Turck, Filip De and Abbeel, Pieter},
  biburl = {http://www.bibsonomy.org/bibtex/21df4dd56279cc97c5fb4a1ba6a0bae03/dblp},
  ee = {http://arxiv.org/abs/1605.09674},
  interhash = {763241eae1cbd027367f9be7c810781e},
  intrahash = {1df4dd56279cc97c5fb4a1ba6a0bae03},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2016-06-02T11:36:52.000+0200},
  title = {Curiosity-driven Exploration in Deep Reinforcement Learning via Bayesian Neural Networks.},
  url = {http://dblp.uni-trier.de/db/journals/corr/corr1605.html#HouthooftCDSTA16},
  volume = {abs/1605.09674},
  year = 2016
}


@article{VIME,
  author    = {Rein Houthooft and
               Xi Chen and
               Yan Duan and
               John Schulman and
               Filip De Turck and
               Pieter Abbeel},
  title     = {Curiosity-driven Exploration in Deep Reinforcement Learning via Bayesian
               Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1605.09674},
  year      = {2016},
  url       = {http://arxiv.org/abs/1605.09674},
  timestamp = {Wed, 07 Jun 2017 14:40:45 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/HouthooftCDSTA16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{empowerment,
  author    = {Tobias Jung and
               Daniel Polani and
               Peter Stone},
  title     = {Empowerment for Continuous Agent-Environment Systems},
  journal   = {CoRR},
  volume    = {abs/1201.6583},
  year      = {2012},
  url       = {http://arxiv.org/abs/1201.6583},
  timestamp = {Wed, 07 Jun 2017 14:41:24 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/abs-1201-6583},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@ARTICLE{empowerment2,
   author = {{Mohamed}, S. and {Jimenez Rezende}, D.},
    title = "{Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1509.08731},
 primaryClass = "stat.ML",
 keywords = {Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Learning},
     year = 2015,
    month = sep,
   adsurl = {http://adsabs.harvard.edu/abs/2015arXiv150908731M},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@ARTICLE{empowerment3,
   author = {{Salge}, C. and {Glackin}, C. and {Polani}, D.},
    title = "{Empowerment -- an Introduction}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1310.1863},
 primaryClass = "cs.AI",
 keywords = {Computer Science - Artificial Intelligence, Computer Science - Information Theory, Nonlinear Sciences - Adaptation and Self-Organizing Systems},
     year = 2013,
    month = oct,
   adsurl = {http://adsabs.harvard.edu/abs/2013arXiv1310.1863S},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{controlempowerment,
  author    = {Karol Gregor and
               Danilo Jimenez Rezende and
               Daan Wierstra},
  title     = {Variational Intrinsic Control},
  journal   = {CoRR},
  volume    = {abs/1611.07507},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.07507},
  timestamp = {Wed, 07 Jun 2017 14:40:19 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/GregorRW16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@ARTICLE{neuronebayes,
   author = {{Blundell}, C. and {Cornebise}, J. and {Kavukcuoglu}, K. and 
	{Wierstra}, D.},
    title = "{Weight Uncertainty in Neural Networks}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1505.05424},
 primaryClass = "stat.ML",
 keywords = {Statistics - Machine Learning, Computer Science - Learning},
     year = 2015,
    month = may,
   adsurl = {http://adsabs.harvard.edu/abs/2015arXiv150505424B},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@INPROCEEDINGS{policygradient,
    author = {Richard S. Sutton and David Mcallester and Satinder Singh and Yishay Mansour},
    title = {Policy gradient methods for reinforcement learning with function approximation},
    booktitle = {In Advances in Neural Information Processing Systems 12},
    year = {2000},
    pages = {1057--1063},
    publisher = {MIT Press}
}

@Article{Williams1992,
author="Williams, Ronald J.",
title="Simple statistical gradient-following algorithms for connectionist reinforcement learning",
journal="Machine Learning",
year="1992",
month="May",
day="01",
volume="8",
number="3",
pages="229--256",
abstract="This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units. These algorithms, called REINFORCE algorithms, are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reinforcement tasks, and they do this without explicitly computing gradient estimates or even storing information from which such estimates could be computed. Specific examples of such algorithms are presented, some of which bear a close relationship to certain existing algorithms while others are novel but potentially interesting in their own right. Also given are results that show how such algorithms can be naturally integrated with backpropagation. We close with a brief discussion of a number of additional issues surrounding the use of such algorithms, including what is known about their limiting behaviors as well as further considerations that might be used to help develop similar but potentially more powerful reinforcement learning algorithms.",
issn="1573-0565",
doi="10.1007/BF00992696",
url="https://doi.org/10.1007/BF00992696"
}


